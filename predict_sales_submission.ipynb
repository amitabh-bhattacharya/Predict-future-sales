{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are importing the necessary packages.\n",
    "# Matplotlib & Seaborn packages are used for plotting\n",
    "# RandomForestRegressor tree model is used here for modelling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from itertools import product\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f0a1c729d4fb3d6609f9dfb163ebe92fa9dc654c"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset in notebook. \n",
    "# The csv files should be present in the root directory.\n",
    "items = pd.read_csv('data\\\\items.csv')\n",
    "shops = pd.read_csv('data\\\\shops.csv')\n",
    "cats = pd.read_csv('data\\\\item_categories.csv')\n",
    "train = pd.read_csv('data\\\\sales_train.csv')\n",
    "test  = pd.read_csv('data\\\\test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "5a864412fafc3129a3e9bd5bb1f18a7cf0c62935"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19ca124e940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the seaborn boxplots to visualize the outliers\n",
    "plt.figure(figsize = (8,2))\n",
    "sns.boxplot(train.item_cnt_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7e621535d112603c60aeb2c2f83dbbf96d36b732"
   },
   "outputs": [],
   "source": [
    "# Removing the outliers from the train data. \n",
    "# I considered more than 1000 items sold in a day by a shop as an outlier. Not considering it for the training.\n",
    "train = train[train.item_cnt_day < 1001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "12fae4c8d0c8f3e817307d1e0ffc6831e9a8d696"
   },
   "outputs": [],
   "source": [
    "# Shop name field is embedded with the city name of the shop. Below we are extracting the city information from shop name. \n",
    "# City information can be vital as we can compute sales based on city. Popular cities generally have higher sales.\n",
    "# Then we label encode the city name\n",
    "\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops = shops[['shop_id','city_code']]\n",
    "\n",
    "# Similaryly item category name consistes of item type and subtype. \n",
    "# Below we are extracting the item type and subtype information from item category name. \n",
    "# Item type and subtype information can be vital as we can compute sales based on item type or subtype.\n",
    "# Then we label encode the item type and subtype\n",
    "\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "# if subtype is nan then putting type information\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "# Item name is no more required so dropping the field.\n",
    "items.drop(['item_name'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7626c7455ea71b65894c6c866519df15080fa2ac"
   },
   "outputs": [],
   "source": [
    "# Preparing all combinations of month, shop id, and item id if there is a sale of an item by a shop in a particular month.\n",
    "# Preparing the base_train which consists of the training features. Later we keep merging new engineered features \n",
    "# in base_train. The base_train will contain all features and labels required for the training.\n",
    "base_train = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num == i]\n",
    "    base_train.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype = 'int16'))\n",
    "    \n",
    "base_train = pd.DataFrame(np.vstack(base_train), columns = cols)\n",
    "base_train['date_block_num'] = base_train['date_block_num'].astype(np.int8)\n",
    "base_train['shop_id'] = base_train['shop_id'].astype(np.int8)\n",
    "base_train['item_id'] = base_train['item_id'].astype(np.int16)\n",
    "base_train.sort_values(cols, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7dd27181918fc7df89676e24d72130d183929d2d"
   },
   "outputs": [],
   "source": [
    "# Aggregating the item count day to compute the monthly item sale (item_cnt_month). \n",
    "# item_cnt_month field is the desired label to be predicted for test data in this problem.\n",
    "# Grouping by month, shop id, item id\n",
    "group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = cols, how = 'left')\n",
    "base_train['item_cnt_month'] = (base_train['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "29d02bdb4fa768577607bf735b918ca81da85d41"
   },
   "outputs": [],
   "source": [
    "# Test dataset preparation. Incorporating the date_block_num = 34 in test dataset. \n",
    "# Downsizing the field type to consume less memory.\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "177fbbab94c8057d67d61357d29581248468a74d"
   },
   "outputs": [],
   "source": [
    "# Concatanating the base_train and test dataset. This merging is required as we will now compute new engineered features.\n",
    "base_train = pd.concat([base_train, test], ignore_index = True, sort = False, keys = cols)\n",
    "base_train.fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7dfd5df3e2bcaee4c312f3979736f52c40f2560f"
   },
   "outputs": [],
   "source": [
    "# Joining base_train with shops (to get city code), items (to get item_category) and cats (to get item type/sub-type)\n",
    "base_train = pd.merge(base_train, shops, on = ['shop_id'], how = 'left')\n",
    "base_train = pd.merge(base_train, items, on = ['item_id'], how = 'left')\n",
    "base_train = pd.merge(base_train, cats, on = ['item_category_id'], how = 'left')\n",
    "base_train['city_code'] = base_train['city_code'].astype(np.int8)\n",
    "base_train['item_category_id'] = base_train['item_category_id'].astype(np.int8)\n",
    "base_train['type_code'] = base_train['type_code'].astype(np.int8)\n",
    "base_train['subtype_code'] = base_train['subtype_code'].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "9cd7bcc7643ce4545475e8e6f80d09a979aac42d"
   },
   "outputs": [],
   "source": [
    "# Target lags function definition. This would be heavily called for feature engineering of sales lag features.\n",
    "def Lag_FeatureEngineering(data_frame, lag_list, column):\n",
    "    temp = data_frame[['date_block_num', 'shop_id', 'item_id', column]]\n",
    "    \n",
    "    for lag in lag_list:\n",
    "        shifted_df = temp.copy()\n",
    "        shifted_df.columns = ['date_block_num', 'shop_id', 'item_id', column + '_lag_' + str(i)]\n",
    "        shifted_df['date_block_num'] += lag\n",
    "        data_frame = pd.merge(data_frame, shifted_df, on = ['date_block_num', 'shop_id', 'item_id'], how = 'left')\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "78bf7ece93ebc4629ad0e48cd6a9927788d8706d"
   },
   "outputs": [],
   "source": [
    "# Computing the lag for item count month\n",
    "base_train = Lag_FeatureEngineering(base_train, [1,2,3,6,12], 'item_cnt_month')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "763aca242154ea10fa0a62fffadb4ef90e9532d6"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month\n",
    "group = base_train.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'Month_MeanEncoding' ]\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num'], how = 'left')\n",
    "base_train['Month_MeanEncoding'] = base_train['Month_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_MeanEncoding')\n",
    "base_train.drop(['Month_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "fc9166c4e678ebb99d03566f1751b7d4b5c690d2"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, item id\n",
    "group = base_train.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_Item_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'item_id'], how = 'left')\n",
    "base_train['Month_Item_MeanEncoding'] = base_train['Month_Item_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1,2,3,6,12], 'Month_Item_MeanEncoding')\n",
    "base_train.drop(['Month_Item_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "73f2552c403c5f67bbf07f28d69efcc015d00f32"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, shop id\n",
    "group = base_train.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_Shop_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num','shop_id'], how = 'left')\n",
    "base_train['Month_Shop_MeanEncoding'] = base_train['Month_Shop_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1,2,3,6,12], 'Month_Shop_MeanEncoding')\n",
    "base_train.drop(['Month_Shop_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c3948a9b206bc480b31385c29a713aa49747de19"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, item category id\n",
    "group = base_train.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_ItemCat_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num','item_category_id'], how = 'left')\n",
    "base_train['Month_ItemCat_MeanEncoding'] = base_train['Month_ItemCat_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_ItemCat_MeanEncoding')\n",
    "base_train.drop(['Month_ItemCat_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bf98335755692f0d7666eeac2db1961692f09a16"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, shop id, item category id\n",
    "group = base_train.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_Shop_ItemCat_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'shop_id', 'item_category_id'], how = 'left')\n",
    "base_train['Month_Shop_ItemCat_MeanEncoding'] = base_train['Month_Shop_ItemCat_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_Shop_ItemCat_MeanEncoding')\n",
    "base_train.drop(['Month_Shop_ItemCat_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "3959603ea684eb3cbfd17d557399caa6e9da88e4"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, shop id, item type\n",
    "group = base_train.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_Shop_ItemType_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'shop_id', 'type_code'], how = 'left')\n",
    "base_train['Month_Shop_ItemType_MeanEncoding'] = base_train['Month_Shop_ItemType_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_Shop_ItemType_MeanEncoding')\n",
    "base_train.drop(['Month_Shop_ItemType_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "39f66d2e30f691237aa5d41ff9fc3a0eb7e9a788"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, shop id, item subtype\n",
    "group = base_train.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_Shop_ItemSubtype_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'shop_id', 'subtype_code'], how = 'left')\n",
    "base_train['Month_Shop_ItemSubtype_MeanEncoding'] = base_train['Month_Shop_ItemSubtype_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_Shop_ItemSubtype_MeanEncoding')\n",
    "base_train.drop(['Month_Shop_ItemSubtype_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "87d57d01beb0830138dabae79b4022d4c6a9cc12"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, city\n",
    "group = base_train.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_City_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'city_code'], how = 'left')\n",
    "base_train['Month_City_MeanEncoding'] = base_train['Month_City_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_City_MeanEncoding')\n",
    "base_train.drop(['Month_City_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3cd5232ad63357dacebe9d223cc93dd669132bb7"
   },
   "outputs": [],
   "source": [
    "# Mean encoding grouped by month, item type\n",
    "group = base_train.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['Month_ItemType_MeanEncoding']\n",
    "group.reset_index(inplace = True)\n",
    "\n",
    "base_train = pd.merge(base_train, group, on = ['date_block_num', 'type_code'], how = 'left')\n",
    "base_train['Month_ItemType_MeanEncoding'] = base_train['Month_ItemType_MeanEncoding'].astype(np.float16)\n",
    "base_train = Lag_FeatureEngineering(base_train, [1], 'Month_ItemType_MeanEncoding')\n",
    "base_train.drop(['Month_ItemType_MeanEncoding'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test split\n",
    "test_data = base_train[base_train.date_block_num == 34].fillna(0)\n",
    "train_data = base_train[base_train.date_block_num < 34].fillna(0)\n",
    "\n",
    "# Month 22 is choosen to have validation set mimic the test set. 22 is November month\n",
    "train_month_numbers = list(set(base_train['date_block_num']) - set([22,31,32,33]))\n",
    "val_month_numbers = list(set([22,31,32,33]))\n",
    "\n",
    "temp_result = ~base_train.columns.isin(['item_cnt_month'])\n",
    "train_columns = base_train.columns[temp_result]\n",
    "\n",
    "X_train = train_data[train_data.date_block_num.isin(train_month_numbers)][train_columns]\n",
    "X_val =  train_data[train_data.date_block_num.isin(val_month_numbers)][train_columns]\n",
    "X_test = test_data[train_columns]\n",
    "\n",
    "y_train = train_data[train_data.date_block_num.isin(train_month_numbers)]['item_cnt_month']\n",
    "y_val =  train_data[train_data.date_block_num.isin(val_month_numbers)]['item_cnt_month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571990219438435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "# RandomForest model; Metrics: root mean squared error calculation\n",
    "rmse = 999999\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators = 20, max_depth = 8, criterion = 'mse', n_jobs = -1, random_state = 42)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Saving the model for later use\n",
    "filename = 'rfr_model.sav'\n",
    "pickle.dump(rfr, open(filename, 'wb'))\n",
    " \n",
    "# loading the model from disk\n",
    "loaded_rfr = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "pred_val = loaded_rfr.predict(X_val).clip(0, 20)  \n",
    "mse_val = mean_squared_error(y_val, pred_val)\n",
    "rmse = np.sqrt(mse_val) \n",
    "\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on Test data \n",
    "pred_test = loaded_rfr.predict(X_test).clip(0, 20)\n",
    "\n",
    "# Preparing for the submission\n",
    "X_test = X_test[['shop_id', 'item_id']]\n",
    "X_test['item_cnt_month'] = pred_test\n",
    "submission = test[['ID', 'shop_id', 'item_id']].merge(X_test, on = ['shop_id', 'item_id'], how = 'left').fillna(0)\n",
    "submission[['ID', 'item_cnt_month']].to_csv('submission.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
